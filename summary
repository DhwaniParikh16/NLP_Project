import xml.etree.ElementTree as ET

import nltk

import re

import os

from nltk import sent_tokenize, word_tokenize, PorterStemmer

from nltk.corpus import stopwords  





filedir = 'C:/Users/dhwan/OneDrive/Desktop/NLP_Project/AllPublicXML/NCT0000xxxx'



stopWords = set(stopwords.words("english"))



for file in os.listdir(filedir):

    print('Data of File : ' + file[:-4] + '\n')

    tree = ET.parse(filedir +'/'+ file)

    root=tree.getroot()

    tags=['brief_title','brief_summary','detailed_description','condition','keyword']

    tags_block = ['brief_summary','detailed_description']

    summary = ''

    for el in root.findall('.//'):

        if el.tag in tags:

            if el.tag in tags_block:

                    summary = summary +' Brief Summary:' + re.sub(r'\s+',' ',el.find('textblock').text)+ '\n'

            else:

                if el.tag== 'brief_title':

                    summary=summary +  'Title:' +re.sub(r'\s+',' ',el.text)+ '.' + '\n'

                if el.tag=='url':

                    summary=summary + 'URL:'+ re.sub(r'\s+',' ',el.text)+ '.' + '\n'
                    
                if el.tag=='phase':

                    summary=summary + 'Phase:'+ re.sub(r'\s+',' ',el.text)+ '.' + '\n'
                    

    print(summary)         

    text=summary

    words = word_tokenize(text) 

       

    # Creating a frequency table to keep the  

    # score of each word 

       

    freqTable = dict() 

    for word in words: 

        word = word.lower() 

        if word in stopWords: 

            continue

        if word in freqTable: 

            freqTable[word] += 1

        else: 

            freqTable[word] = 1

       

    # Creating a dictionary to keep the score 

    # of each sentence 

    sentences = sent_tokenize(text) 

    sentenceValue = dict() 

       

    for sentence in sentences: 

        for word, freq in freqTable.items(): 

            if word in sentence.lower(): 

                if sentence in sentenceValue: 

                    sentenceValue[sentence] += freq 

                else: 

                    sentenceValue[sentence] = freq 

       

       

       

    sumValues = 0

    for sentence in sentenceValue: 

        sumValues += sentenceValue[sentence] 

       

    # Average value of a sentence from the original text 

       

    average = int(sumValues / len(sentenceValue)) 

       

    # Storing sentences into our summary. 

    summary = '' 

    for sentence in sentences: 

        if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)): 

            summary += " " + sentence 

    print(summary) 


'''

required_header

id_info

brief_title

sponsors

source

brief_summary

overall_status

study_type

has_expanded_access

study_design_info

condition

eligibility

location

location_countries

verification_date

study_first_submitted

study_first_submitted_qc

study_first_posted

last_update_submitted

last_update_submitted_qc

last_update_posted

keyword

condition_browse

'''

