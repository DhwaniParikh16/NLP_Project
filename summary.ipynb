import xml.etree.ElementTree as ET

import nltk

import re

import os

from nltk import sent_tokenize, word_tokenize, PorterStemmer

from nltk.corpus import stopwords 

#### Change the filedir variable with the folder name containing all xml datas ###  



filedir = 'C:/Users/mansi/Downloads/AllPublicXML/NCT0000xxxx'



stopWords = set(stopwords.words("english"))



for file in os.listdir(filedir):

    print('Data of File : ' + file[:-4] + '\n')

    tree = ET.parse(filedir +'/'+ file)

    root=tree.getroot()

    tags=['brief_title','brief_summary','detailed_description','condition','keyword','phase','eligibility','url']

    tags_block = ['brief_summary']

    summary = ''

    for el in root.findall('.//'):

        if el.tag in tags:

            if el.tag in tags_block:

                    summary = summary + 'Brief Summary : ' + re.sub(r'\s+',' ',el.find('textblock').text)+ '\n\n'

            else:

                if el.tag== 'brief_title':

                    summary=summary +  'Title = ' +re.sub(r'\s+',' ',el.text)+ '.' + '\n\n'

            
            if el.tag=='url':
                summary = summary +  'URL : ' +re.sub(r'\s+',' ',el.text)+ '.' + '\n\n'
            
            if el.tag=='phase':
                 summary = summary +  'Phase : ' +re.sub(r'\s+',' ',el.text)+ '.' + '\n\n'

    print(summary)         

    text=summary

    words = word_tokenize(text) 

       

    # Creating a frequency table to keep the  

    # score of each word 

       

    freqTable = dict() 

    for word in words: 

        word = word.lower() 

        if word in stopWords: 

            continue

        if word in freqTable: 

            freqTable[word] += 1

        else: 

            freqTable[word] = 1

       

    # Creating a dictionary to keep the score 

    # of each sentence 

    sentences = sent_tokenize(text) 

    sentenceValue = dict() 

       

    for sentence in sentences: 

        for word, freq in freqTable.items(): 

            if word in sentence.lower(): 

                if sentence in sentenceValue: 

                    sentenceValue[sentence] += freq 

                else: 

                    sentenceValue[sentence] = freq 

       

       

       

    sumValues = 0

    for sentence in sentenceValue: 

        sumValues += sentenceValue[sentence] 

       

    # Average value of a sentence from the original text 

       

    average = int(sumValues / len(sentenceValue)) 

       

    # Storing sentences into our summary. 

    summary = '' 

    for sentence in sentences: 

        if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)): 

            summary += " " + sentence 

    print(summary+ '\n\n\n') 
